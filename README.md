# Autograding Using LLMs

## Workflow

1. Instructor provides problem statement and reference solution
2. Reference solution is required
    1. Provided by instructor
    2. Generated by AI, but approved/edited by instructor
3. Find problem type (matching output/unit testing/more complex), or have the instructor select it
4. Find assignment's programming language, or have the instructor select it
5. LLM: Generate detailed problem description from the provided problem description and reference solution
6. LLM: Generate test cases based on the detailed problem description and the reference solution:
    1. Find edge cases
    2. Reflect on their correctness and coverage 
    3. Generate tests (edge + random)
       - For matching output: Tests are only inputs.
       - For unit tests: tests compare the result of calling the student's function with the result of calling the instructor solution on the same input
       - Note: The LLM was not able to run the reference solution to generate the outputs. It expects wrong outputs for the tests, even when it says it did run the solution to generate the expected outputs
7. Run tests and drop any test that crashes the instructor solution